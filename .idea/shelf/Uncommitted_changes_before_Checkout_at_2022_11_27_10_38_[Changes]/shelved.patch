Index: dreambooth_runpod_joepenna.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>{\r\n \"cells\": [\r\n  {\r\n   \"cell_type\": \"markdown\",\r\n   \"source\": [\r\n    \"## Build Environment\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%% md\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# Download the 1.4 sd model\\n\",\r\n    \"from IPython.display import clear_output\\n\",\r\n    \"\\n\",\r\n    \"from huggingface_hub import hf_hub_download\\n\",\r\n    \"downloaded_model_path = hf_hub_download(\\n\",\r\n    \" repo_id=\\\"stabilityai/stable-diffusion-2\\\",\\n\",\r\n    \" filename=\\\"768-v-ema.ckpt\\\",\\n\",\r\n    \" use_auth_token=True\\n\",\r\n    \")\\n\",\r\n    \"\\n\",\r\n    \"# Move the sd-v1-4.ckpt to the root of this directory as \\\"model.ckpt\\\"\\n\",\r\n    \"actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\\n\",\r\n    \"!mv {actual_locations_of_model_blob[-1]} sd2.ckpt\\n\",\r\n    \"clear_output()\\n\",\r\n    \"print(\\\"✅ model.ckpt successfully downloaded\\\")\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"def get_format_ts():\\n\",\r\n    \"    import time\\n\",\r\n    \"    from datetime import datetime\\n\",\r\n    \"    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\\n\",\r\n    \"\\n\",\r\n    \"def get_img_urls(file_name):\\n\",\r\n    \"    urls = []\\n\",\r\n    \"    with open(file_name, \\\"r\\\") as f:\\n\",\r\n    \"        lines = f.readlines()\\n\",\r\n    \"        urls = [r.replace(\\\"\\\\n\\\", \\\"\\\") for r in lines]\\n\",\r\n    \"    print(urls)\\n\",\r\n    \"    return urls\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"def generate_training_images(urls, save_path):\\n\",\r\n    \"    import os\\n\",\r\n    \"    import requests\\n\",\r\n    \"    from io import BytesIO\\n\",\r\n    \"    from PIL import Image\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"    def image_grid(imgs, rows, cols):\\n\",\r\n    \"     assert len(imgs) == rows*cols\\n\",\r\n    \"\\n\",\r\n    \"     w, h = imgs[0].size\\n\",\r\n    \"     grid = Image.new('RGB', size=(cols*w, rows*h))\\n\",\r\n    \"     grid_w, grid_h = grid.size\\n\",\r\n    \"\\n\",\r\n    \"     for i, img in enumerate(imgs):\\n\",\r\n    \"      grid.paste(img, box=(i%cols*w, i//cols*h))\\n\",\r\n    \"     return grid\\n\",\r\n    \"\\n\",\r\n    \"    def download_image(url):\\n\",\r\n    \"     try:\\n\",\r\n    \"      response = requests.get(url)\\n\",\r\n    \"     except:\\n\",\r\n    \"      return None\\n\",\r\n    \"     return Image.open(BytesIO(response.content)).convert(\\\"RGB\\\")\\n\",\r\n    \"\\n\",\r\n    \"    images = list(filter(None,[download_image(url) for url in urls]))\\n\",\r\n    \"    save_path = \\\"./training_images/{}\\\".format(save_path)\\n\",\r\n    \"    if not os.path.exists(save_path):\\n\",\r\n    \"     os.mkdir(save_path)\\n\",\r\n    \"    [image.save(f\\\"{save_path}/{i}.png\\\", format=\\\"png\\\") for i, image in enumerate(images)]\\n\",\r\n    \"    image_grid(images, 1, len(images))\\n\",\r\n    \"\\n\",\r\n    \"\\n\",\r\n    \"def generate_reg_images(class_token, resume_model=\\\"v1-5.ckpt\\\", self_generated_files_count=200):\\n\",\r\n    \"    !rm -rf ./outputs\\n\",\r\n    \"    !python scripts/stable_txt2img.py \\\\\\n\",\r\n    \"     --seed 10 \\\\\\n\",\r\n    \"     --ddim_eta 0.0 \\\\\\n\",\r\n    \"     --n_samples 1 \\\\\\n\",\r\n    \"     --n_iter {self_generated_files_count} \\\\\\n\",\r\n    \"     --scale 10.0 \\\\\\n\",\r\n    \"     --ddim_steps 50 \\\\\\n\",\r\n    \"     --ckpt resume_model/{resume_model} \\\\\\n\",\r\n    \"     --prompt {class_token}\\n\",\r\n    \"\\n\",\r\n    \"    !mkdir -p regularization_images/{class_token}\\n\",\r\n    \"    !mv outputs/txt2img-samples/*.png regularization_images/{class_token}\\n\",\r\n    \"\\n\",\r\n    \"def train_concept(\\n\",\r\n    \"    class_token, \\n\",\r\n    \"    prompt_token, \\n\",\r\n    \"    resume_model=\\\"v1-5.ckpt\\\", \\n\",\r\n    \"    is_gen_training_images=False, \\n\",\r\n    \"    is_gen_reg_images=False, \\n\",\r\n    \"    reg_count=1000, \\n\",\r\n    \"    training_image_path=None,\\n\",\r\n    \"    max_training_steps=2000):\\n\",\r\n    \"    # write logs\\n\",\r\n    \"    with open(\\\"./logs/training_logs.txt\\\", \\\"a+\\\") as f:\\n\",\r\n    \"        content = \\\"ts: {}, from: {}, to: {}\\\\n\\\".format(get_format_ts(), resume_model.replace(\\\".ckpt\\\", \\\"\\\"), prompt_token)\\n\",\r\n    \"        f.writelines(content)\\n\",\r\n    \"        f.close()\\n\",\r\n    \"    if is_gen_training_images:\\n\",\r\n    \"        training_image_path = prompt_token + \\\"_\\\" + get_format_ts()\\n\",\r\n    \"        urls = get_img_urls(\\\"./img_urls/{}.txt\\\".format(prompt_token))\\n\",\r\n    \"        generate_training_images(urls, training_image_path)\\n\",\r\n    \"    else:\\n\",\r\n    \"        assert training_image_path is not None\\n\",\r\n    \"    \\n\",\r\n    \"    if is_gen_reg_images:\\n\",\r\n    \"        self_generated_files_count = reg_count\\n\",\r\n    \"        generate_reg_images(class_token, resume_model, self_generated_files_count=self_generated_files_count)\\n\",\r\n    \"    \\n\",\r\n    \"    project_name = prompt_token\\n\",\r\n    \"    \\n\",\r\n    \"    # MAX STEPS\\n\",\r\n    \"    # Match class_word to the category of the regularization images you chose above.\\n\",\r\n    \"    class_word = class_token # typical uses are \\\"man\\\", \\\"person\\\", \\\"woman\\\"\\n\",\r\n    \"    # This is the unique token you are incorporating into the stable diffusion model.\\n\",\r\n    \"    token = prompt_token\\n\",\r\n    \"\\n\",\r\n    \"    reg_data_root = \\\"./regularization_images/\\\" + class_token\\n\",\r\n    \"\\n\",\r\n    \"    !rm -rf training_images/.ipynb_checkpoints\\n\",\r\n    \"    !python \\\"main.py\\\" \\\\\\n\",\r\n    \"     --base configs/stable-diffusion/v1-finetune_unfrozen-mu.yaml \\\\\\n\",\r\n    \"     -t \\\\\\n\",\r\n    \"     --reg_data_root \\\"{reg_data_root}\\\" \\\\\\n\",\r\n    \"     -n \\\"{project_name}\\\" \\\\\\n\",\r\n    \"     --gpus 0, \\\\\\n\",\r\n    \"     --data_root \\\"./training_images/{training_image_path}\\\" \\\\\\n\",\r\n    \"     --max_training_steps {max_training_steps} \\\\\\n\",\r\n    \"     --class_word \\\"{class_word}\\\" \\\\\\n\",\r\n    \"     --token \\\"{token}\\\" \\\\\\n\",\r\n    \"     --no-test\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"%env USE_MEMORY_EFFICIENT_ATTENTION=1\\n\",\r\n    \"# 定义新变量\\n\",\r\n    \"def get_format_ts():\\n\",\r\n    \"    import time\\n\",\r\n    \"    from datetime import datetime\\n\",\r\n    \"    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\\n\",\r\n    \"class_token = \\\"style\\\"  # 这个变量是要训练的内容的类目，要用具有实际含义的词，如要训练一种特殊风格的椅子，就用chair, 训练特殊风格的人物，就用person, etc， 如果是一类风格的话，就用style\\n\",\r\n    \"prompt_token = \\\"test\\\" # 这个变量要用模型当中没有出现过的词语\\n\",\r\n    \"resume_model = \\\"model.ckpt\\\"  # 注意，这里是模型训练的启动点，意思是模型基于已有的哪个模型训练，在训练前问下良伟\\n\",\r\n    \"# resume_model = \\\"model.ckpt\\\"\\n\",\r\n    \"\\n\",\r\n    \"is_gen_training_images = False\\n\",\r\n    \"is_gen_reg_images = False\\n\",\r\n    \"reg_count = 4\\n\",\r\n    \"training_image_path = \\\"test_20221126-053249\\\"\\n\",\r\n    \"max_training_steps=100\\n\",\r\n    \"train_concept(class_token, prompt_token, resume_model, is_gen_training_images, is_gen_reg_images, reg_count, training_image_path,max_training_steps)\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# BUILD ENV\\n\",\r\n    \"!pip install omegaconf\\n\",\r\n    \"!pip install einops\\n\",\r\n    \"!pip install pytorch-lightning==1.6.5\\n\",\r\n    \"!pip install test-tube\\n\",\r\n    \"!pip install transformers\\n\",\r\n    \"!pip install kornia\\n\",\r\n    \"!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\\n\",\r\n    \"!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\\n\",\r\n    \"!pip install setuptools==59.5.0\\n\",\r\n    \"!pip install pillow==9.0.1\\n\",\r\n    \"!pip install torchmetrics==0.6.0\\n\",\r\n    \"!pip install -e .\\n\",\r\n    \"!pip install protobuf==3.20.1\\n\",\r\n    \"!pip install gdown\\n\",\r\n    \"!pip install -qq diffusers[\\\"training\\\"]==0.3.0 transformers ftfy\\n\",\r\n    \"!pip install -qq \\\"ipywidgets>=7,<8\\\"\\n\",\r\n    \"!pip install huggingface_hub\\n\",\r\n    \"!pip install ipywidgets==7.7.1\\n\",\r\n    \"!pip install captionizer==1.0.1\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# Download the 1.4 sd model\\n\",\r\n    \"\\n\",\r\n    \"from huggingface_hub import hf_hub_download\\n\",\r\n    \"downloaded_model_path = hf_hub_download(\\n\",\r\n    \" repo_id=\\\"CompVis/stable-diffusion-v-1-4-original\\\",\\n\",\r\n    \" filename=\\\"sd-v1-4.ckpt\\\",\\n\",\r\n    \" use_auth_token=\\\"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\\\"\\n\",\r\n    \")\\n\",\r\n    \"\\n\",\r\n    \"# Move the sd-v1-4.ckpt to the root of this directory as \\\"model.ckpt\\\"\\n\",\r\n    \"actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\\n\",\r\n    \"!mv {actual_locations_of_model_blob[-1]} model.ckpt\\n\",\r\n    \"print(\\\"✅ model.ckpt successfully downloaded\\\")\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# BUILD ENV\\n\",\r\n    \"!pip install omegaconf\\n\",\r\n    \"!pip install einops\\n\",\r\n    \"!pip install pytorch-lightning==1.6.5\\n\",\r\n    \"!pip install test-tube\\n\",\r\n    \"!pip install transformers\\n\",\r\n    \"!pip install kornia\\n\",\r\n    \"!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\\n\",\r\n    \"!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\\n\",\r\n    \"!pip install setuptools==59.5.0\\n\",\r\n    \"!pip install pillow==9.0.1\\n\",\r\n    \"!pip install torchmetrics==0.6.0\\n\",\r\n    \"!pip install -e .\\n\",\r\n    \"!pip install protobuf==3.20.1\\n\",\r\n    \"!pip install gdown\\n\",\r\n    \"!pip install -qq diffusers[\\\"training\\\"]==0.3.0 transformers ftfy\\n\",\r\n    \"!pip install -qq \\\"ipywidgets>=7,<8\\\"\\n\",\r\n    \"!pip install huggingface_hub\\n\",\r\n    \"!pip install ipywidgets==7.7.1\\n\",\r\n    \"!pip install captionizer==1.0.1\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [\r\n    \"# Download the 1.4 sd model\\n\",\r\n    \"\\n\",\r\n    \"from huggingface_hub import hf_hub_download\\n\",\r\n    \"downloaded_model_path = hf_hub_download(\\n\",\r\n    \" repo_id=\\\"CompVis/stable-diffusion-v-1-4-original\\\",\\n\",\r\n    \" filename=\\\"sd-v1-4.ckpt\\\",\\n\",\r\n    \" use_auth_token=\\\"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\\\"\\n\",\r\n    \")\\n\",\r\n    \"\\n\",\r\n    \"# Move the sd-v1-4.ckpt to the root of this directory as \\\"model.ckpt\\\"\\n\",\r\n    \"actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\\n\",\r\n    \"!mv {actual_locations_of_model_blob[-1]} model.ckpt\\n\",\r\n    \"print(\\\"✅ model.ckpt successfully downloaded\\\")\"\r\n   ],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  },\r\n  {\r\n   \"cell_type\": \"code\",\r\n   \"execution_count\": null,\r\n   \"outputs\": [],\r\n   \"source\": [],\r\n   \"metadata\": {\r\n    \"collapsed\": false,\r\n    \"pycharm\": {\r\n     \"name\": \"#%%\\n\"\r\n    }\r\n   }\r\n  }\r\n ],\r\n \"metadata\": {\r\n  \"colab\": {\r\n   \"collapsed_sections\": [],\r\n   \"provenance\": []\r\n  },\r\n  \"kernelspec\": {\r\n   \"display_name\": \"Python 3 (ipykernel)\",\r\n   \"language\": \"python\",\r\n   \"name\": \"python3\"\r\n  },\r\n  \"language_info\": {\r\n   \"codemirror_mode\": {\r\n    \"name\": \"ipython\",\r\n    \"version\": 3\r\n   },\r\n   \"file_extension\": \".py\",\r\n   \"mimetype\": \"text/x-python\",\r\n   \"name\": \"python\",\r\n   \"nbconvert_exporter\": \"python\",\r\n   \"pygments_lexer\": \"ipython3\",\r\n   \"version\": \"3.10.8\"\r\n  },\r\n  \"vscode\": {\r\n   \"interpreter\": {\r\n    \"hash\": \"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e\"\r\n   }\r\n  }\r\n },\r\n \"nbformat\": 4,\r\n \"nbformat_minor\": 5\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/dreambooth_runpod_joepenna.ipynb b/dreambooth_runpod_joepenna.ipynb
--- a/dreambooth_runpod_joepenna.ipynb	(revision 6443bdcbc536cd99f9b4bf0d35e29a033cb21ca7)
+++ b/dreambooth_runpod_joepenna.ipynb	(date 1669516702681)
@@ -163,36 +163,6 @@
    }
   },
   {
-   "cell_type": "code",
-   "execution_count": null,
-   "outputs": [],
-   "source": [
-    "%env USE_MEMORY_EFFICIENT_ATTENTION=1\n",
-    "# 定义新变量\n",
-    "def get_format_ts():\n",
-    "    import time\n",
-    "    from datetime import datetime\n",
-    "    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\n",
-    "class_token = \"style\"  # 这个变量是要训练的内容的类目，要用具有实际含义的词，如要训练一种特殊风格的椅子，就用chair, 训练特殊风格的人物，就用person, etc， 如果是一类风格的话，就用style\n",
-    "prompt_token = \"test\" # 这个变量要用模型当中没有出现过的词语\n",
-    "resume_model = \"model.ckpt\"  # 注意，这里是模型训练的启动点，意思是模型基于已有的哪个模型训练，在训练前问下良伟\n",
-    "# resume_model = \"model.ckpt\"\n",
-    "\n",
-    "is_gen_training_images = False\n",
-    "is_gen_reg_images = False\n",
-    "reg_count = 4\n",
-    "training_image_path = \"test_20221126-053249\"\n",
-    "max_training_steps=100\n",
-    "train_concept(class_token, prompt_token, resume_model, is_gen_training_images, is_gen_reg_images, reg_count, training_image_path,max_training_steps)"
-   ],
-   "metadata": {
-    "collapsed": false,
-    "pycharm": {
-     "name": "#%%\n"
-    }
-   }
-  },
-  {
    "cell_type": "code",
    "execution_count": null,
    "outputs": [],
