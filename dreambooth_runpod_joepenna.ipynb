{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24985b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model.ckpt successfully downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"stabilityai/stable-diffusion-2\",\n",
    " filename=\"768-v-ema.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} sd2.ckpt\n",
    "clear_output()\n",
    "print(\"✅ model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "def get_format_ts():\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def get_img_urls(file_name):\n",
    "    urls = []\n",
    "    with open(file_name, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        urls = [r.replace(\"\\n\", \"\") for r in lines]\n",
    "    print(urls)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def generate_training_images(urls, save_path):\n",
    "    import os\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "\n",
    "\n",
    "    def image_grid(imgs, rows, cols):\n",
    "     assert len(imgs) == rows*cols\n",
    "\n",
    "     w, h = imgs[0].size\n",
    "     grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "     grid_w, grid_h = grid.size\n",
    "\n",
    "     for i, img in enumerate(imgs):\n",
    "      grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "     return grid\n",
    "\n",
    "    def download_image(url):\n",
    "     try:\n",
    "      response = requests.get(url)\n",
    "     except:\n",
    "      return None\n",
    "     return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    images = list(filter(None,[download_image(url) for url in urls]))\n",
    "    save_path = \"./training_images/{}\".format(save_path)\n",
    "    if not os.path.exists(save_path):\n",
    "     os.mkdir(save_path)\n",
    "    [image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "    image_grid(images, 1, len(images))\n",
    "\n",
    "\n",
    "def generate_reg_images(class_token, resume_model=\"v1-5.ckpt\", self_generated_files_count=200):\n",
    "    !rm -rf ./outputs\n",
    "    !python scripts/stable_txt2img.py \\\n",
    "     --seed 10 \\\n",
    "     --ddim_eta 0.0 \\\n",
    "     --n_samples 1 \\\n",
    "     --n_iter {self_generated_files_count} \\\n",
    "     --scale 10.0 \\\n",
    "     --ddim_steps 50 \\\n",
    "     --ckpt resume_model/{resume_model} \\\n",
    "     --prompt {class_token}\n",
    "\n",
    "    !mkdir -p regularization_images/{class_token}\n",
    "    !mv outputs/txt2img-samples/*.png regularization_images/{class_token}\n",
    "\n",
    "def train_concept(\n",
    "    class_token, \n",
    "    prompt_token, \n",
    "    resume_model=\"v1-5.ckpt\", \n",
    "    is_gen_training_images=False, \n",
    "    is_gen_reg_images=False, \n",
    "    reg_count=1000, \n",
    "    training_image_path=None,\n",
    "    max_training_steps=2000):\n",
    "    # write logs\n",
    "    with open(\"./logs/training_logs.txt\", \"a+\") as f:\n",
    "        content = \"ts: {}, from: {}, to: {}\\n\".format(get_format_ts(), resume_model.replace(\".ckpt\", \"\"), prompt_token)\n",
    "        f.writelines(content)\n",
    "        f.close()\n",
    "    if is_gen_training_images:\n",
    "        training_image_path = prompt_token + \"_\" + get_format_ts()\n",
    "        urls = get_img_urls(\"./img_urls/{}.txt\".format(prompt_token))\n",
    "        generate_training_images(urls, training_image_path)\n",
    "    else:\n",
    "        assert training_image_path is not None\n",
    "    \n",
    "    if is_gen_reg_images:\n",
    "        self_generated_files_count = reg_count\n",
    "        generate_reg_images(class_token, resume_model, self_generated_files_count=self_generated_files_count)\n",
    "    \n",
    "    project_name = prompt_token\n",
    "    \n",
    "    # MAX STEPS\n",
    "    # Match class_word to the category of the regularization images you chose above.\n",
    "    class_word = class_token # typical uses are \"man\", \"person\", \"woman\"\n",
    "    # This is the unique token you are incorporating into the stable diffusion model.\n",
    "    token = prompt_token\n",
    "\n",
    "    reg_data_root = \"./regularization_images/\" + class_token\n",
    "\n",
    "    !rm -rf training_images/.ipynb_checkpoints\n",
    "    !python \"main.py\" \\\n",
    "     --base configs/stable-diffusion/v1-finetune_unfrozen-mu.yaml \\\n",
    "     -t \\\n",
    "     --reg_data_root \"{reg_data_root}\" \\\n",
    "     -n \"{project_name}\" \\\n",
    "     --gpus 0, \\\n",
    "     --data_root \"./training_images/{training_image_path}\" \\\n",
    "     --max_training_steps {max_training_steps} \\\n",
    "     --class_word \"{class_word}\" \\\n",
    "     --token \"{token}\" \\\n",
    "     --no-test\n",
    "#      --actual_resume \"./resume_model/{resume_model}\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2828ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_MEMORY_EFFICIENT_ATTENTION=1\n",
      "['https://i.imgur.com/XQxNKKl.png', 'https://i.imgur.com/V0URx9M.png', 'https://i.imgur.com/XpwebkP.png', 'https://i.imgur.com/5fzZAi3.png', 'https://i.imgur.com/zq4VxSD.png', 'https://i.imgur.com/3mQQhQT.png', 'https://i.imgur.com/CEqf6Cd.png', 'https://i.imgur.com/Snn6rV4.png', 'https://i.imgur.com/Wu9uKtC.png', 'https://i.imgur.com/6af50U3.png', 'https://i.imgur.com/OM4Zq40.png', 'https://i.imgur.com/QIJVOH8.png', 'https://i.imgur.com/75NDeZA.png', 'https://i.imgur.com/PkiWOe8.png', 'https://i.imgur.com/BDxVN0i.png', 'https://i.imgur.com/rPrKSgm.png', 'https://i.imgur.com/pWktxhc.png', 'https://i.imgur.com/lIDxPYC.png', 'https://i.imgur.com/vYrGj5i.png', 'https://i.imgur.com/zJb30eq.png']\n",
      "Global seed set to 10\n",
      "Loading model from resume_model/model.ckpt\n",
      "Global Step: 470000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 292, in <module>\n",
      "    main()\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 195, in main\n",
      "    model = load_model_from_config(config, f\"{opt.ckpt}\")\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 31, in load_model_from_config\n",
      "    model = instantiate_from_config(config.model)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/util.py\", line 87, in instantiate_from_config\n",
      "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()), **kwargs)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 462, in __init__\n",
      "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 91, in __init__\n",
      "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 1534, in __init__\n",
      "    self.aux_diffusion_model = instantiate_from_config(aux_model_config)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/util.py\", line 81, in instantiate_from_config\n",
      "    if not \"target\" in config:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "mv: cannot stat 'outputs/txt2img-samples/*.png': No such file or directory\n",
      "Global seed set to 23\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 631, in <module>\n",
      "    configs = [OmegaConf.load(cfg) for cfg in opt.base]\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 631, in <listcomp>\n",
      "    configs = [OmegaConf.load(cfg) for cfg in opt.base]\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/omegaconf/omegaconf.py\", line 188, in load\n",
      "    obj = yaml.load(f, Loader=get_yaml_loader())\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/__init__.py\", line 81, in load\n",
      "    return loader.get_single_data()\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/constructor.py\", line 49, in get_single_data\n",
      "    node = self.get_single_node()\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 36, in get_single_node\n",
      "    document = self.compose_document()\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 55, in compose_document\n",
      "    node = self.compose_node(None, None)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 133, in compose_mapping_node\n",
      "    item_value = self.compose_node(node, item_key)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/composer.py\", line 127, in compose_mapping_node\n",
      "    while not self.check_event(MappingEndEvent):\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/parser.py\", line 98, in check_event\n",
      "    self.current_event = self.state()\n",
      "  File \"/home/pai/.local/lib/python3.9/site-packages/yaml/parser.py\", line 438, in parse_block_mapping_key\n",
      "    raise ParserError(\"while parsing a block mapping\", self.marks[-1],\n",
      "yaml.parser.ParserError: while parsing a block mapping\n",
      "  in \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/configs/stable-diffusion/v1-finetune_unfrozen-mu.yaml\", line 50, column 9\n",
      "expected <block end>, but found '<block mapping start>'\n",
      "  in \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/configs/stable-diffusion/v1-finetune_unfrozen-mu.yaml\", line 51, column 11\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 896, in <module>\n",
      "    if trainer.global_rank == 0:\n",
      "NameError: name 'trainer' is not defined\n"
     ]
    }
   ],
   "source": [
    "%env USE_MEMORY_EFFICIENT_ATTENTION=1\n",
    "# 定义新变量\n",
    "def get_format_ts():\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\n",
    "class_token = \"style\"  # 这个变量是要训练的内容的类目，要用具有实际含义的词，如要训练一种特殊风格的椅子，就用chair, 训练特殊风格的人物，就用person, etc， 如果是一类风格的话，就用style\n",
    "prompt_token = \"test\" # 这个变量要用模型当中没有出现过的词语\n",
    "resume_model = \"model.ckpt\"  # 注意，这里是模型训练的启动点，意思是模型基于已有的哪个模型训练，在训练前问下良伟\n",
    "# resume_model = \"model.ckpt\"\n",
    "\n",
    "is_gen_training_images = True\n",
    "is_gen_reg_images = True\n",
    "reg_count = 4\n",
    "training_image_path = None\n",
    "max_training_steps=100\n",
    "train_concept(class_token, prompt_token, resume_model, is_gen_training_images, is_gen_reg_images, reg_count, training_image_path,max_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62884b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
