{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b971cc0",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Build Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24985b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ model.ckpt successfully downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"stabilityai/stable-diffusion-2\",\n",
    " filename=\"768-v-ema.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} sd2.ckpt\n",
    "clear_output()\n",
    "print(\"✅ model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "def get_format_ts():\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def get_img_urls(file_name):\n",
    "    urls = []\n",
    "    with open(file_name, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        urls = [r.replace(\"\\n\", \"\") for r in lines]\n",
    "    print(urls)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def generate_training_images(urls, save_path):\n",
    "    import os\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "    from PIL import Image\n",
    "\n",
    "\n",
    "    def image_grid(imgs, rows, cols):\n",
    "     assert len(imgs) == rows*cols\n",
    "\n",
    "     w, h = imgs[0].size\n",
    "     grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "     grid_w, grid_h = grid.size\n",
    "\n",
    "     for i, img in enumerate(imgs):\n",
    "      grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "     return grid\n",
    "\n",
    "    def download_image(url):\n",
    "     try:\n",
    "      response = requests.get(url)\n",
    "     except:\n",
    "      return None\n",
    "     return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    images = list(filter(None,[download_image(url) for url in urls]))\n",
    "    save_path = \"./training_images/{}\".format(save_path)\n",
    "    if not os.path.exists(save_path):\n",
    "     os.mkdir(save_path)\n",
    "    [image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "    image_grid(images, 1, len(images))\n",
    "\n",
    "\n",
    "def generate_reg_images(class_token, resume_model=\"v1-5.ckpt\", self_generated_files_count=200):\n",
    "    !rm -rf ./outputs\n",
    "    !python scripts/stable_txt2img.py \\\n",
    "     --seed 10 \\\n",
    "     --ddim_eta 0.0 \\\n",
    "     --n_samples 1 \\\n",
    "     --n_iter {self_generated_files_count} \\\n",
    "     --scale 10.0 \\\n",
    "     --ddim_steps 50 \\\n",
    "     --ckpt resume_model/{resume_model} \\\n",
    "     --prompt {class_token}\n",
    "\n",
    "    !mkdir -p regularization_images/{class_token}\n",
    "    !mv outputs/txt2img-samples/*.png regularization_images/{class_token}\n",
    "\n",
    "def train_concept(\n",
    "    class_token, \n",
    "    prompt_token, \n",
    "    resume_model=\"v1-5.ckpt\", \n",
    "    is_gen_training_images=False, \n",
    "    is_gen_reg_images=False, \n",
    "    reg_count=1000, \n",
    "    training_image_path=None,\n",
    "    max_training_steps=2000):\n",
    "    # write logs\n",
    "    with open(\"./logs/training_logs.txt\", \"a+\") as f:\n",
    "        content = \"ts: {}, from: {}, to: {}\\n\".format(get_format_ts(), resume_model.replace(\".ckpt\", \"\"), prompt_token)\n",
    "        f.writelines(content)\n",
    "        f.close()\n",
    "    if is_gen_training_images:\n",
    "        training_image_path = prompt_token + \"_\" + get_format_ts()\n",
    "        urls = get_img_urls(\"./img_urls/{}.txt\".format(prompt_token))\n",
    "        generate_training_images(urls, training_image_path)\n",
    "    else:\n",
    "        assert training_image_path is not None\n",
    "    \n",
    "    if is_gen_reg_images:\n",
    "        self_generated_files_count = reg_count\n",
    "        generate_reg_images(class_token, resume_model, self_generated_files_count=self_generated_files_count)\n",
    "    \n",
    "    project_name = prompt_token\n",
    "    \n",
    "    # MAX STEPS\n",
    "    # Match class_word to the category of the regularization images you chose above.\n",
    "    class_word = class_token # typical uses are \"man\", \"person\", \"woman\"\n",
    "    # This is the unique token you are incorporating into the stable diffusion model.\n",
    "    token = prompt_token\n",
    "\n",
    "    reg_data_root = \"./regularization_images/\" + class_token\n",
    "\n",
    "    !rm -rf training_images/.ipynb_checkpoints\n",
    "    !python \"main.py\" \\\n",
    "     --base configs/stable-diffusion/v1-finetune_unfrozen-mu.yaml \\\n",
    "     -t \\\n",
    "     --reg_data_root \"{reg_data_root}\" \\\n",
    "     -n \"{project_name}\" \\\n",
    "     --gpus 0, \\\n",
    "     --data_root \"./training_images/{training_image_path}\" \\\n",
    "     --max_training_steps {max_training_steps} \\\n",
    "     --class_word \"{class_word}\" \\\n",
    "     --token \"{token}\" \\\n",
    "     --no-test \\\n",
    "     --actual_resume \"./resume_model/{resume_model}\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc45348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_MEMORY_EFFICIENT_ATTENTION=1\n",
      "['https://i.imgur.com/XQxNKKl.png', 'https://i.imgur.com/V0URx9M.png', 'https://i.imgur.com/XpwebkP.png', 'https://i.imgur.com/5fzZAi3.png', 'https://i.imgur.com/zq4VxSD.png', 'https://i.imgur.com/3mQQhQT.png', 'https://i.imgur.com/CEqf6Cd.png', 'https://i.imgur.com/Snn6rV4.png', 'https://i.imgur.com/Wu9uKtC.png', 'https://i.imgur.com/6af50U3.png', 'https://i.imgur.com/OM4Zq40.png', 'https://i.imgur.com/QIJVOH8.png', 'https://i.imgur.com/75NDeZA.png', 'https://i.imgur.com/PkiWOe8.png', 'https://i.imgur.com/BDxVN0i.png', 'https://i.imgur.com/rPrKSgm.png', 'https://i.imgur.com/pWktxhc.png', 'https://i.imgur.com/lIDxPYC.png', 'https://i.imgur.com/vYrGj5i.png', 'https://i.imgur.com/zJb30eq.png']\n",
      "Global seed set to 10\n",
      "Loading model from resume_model/model.ckpt\n",
      "Global Step: 470000\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 292, in <module>\n",
      "    main()\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 195, in main\n",
      "    model = load_model_from_config(config, f\"{opt.ckpt}\")\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/scripts/stable_txt2img.py\", line 31, in load_model_from_config\n",
      "    model = instantiate_from_config(config.model)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/util.py\", line 87, in instantiate_from_config\n",
      "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()), **kwargs)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 463, in __init__\n",
      "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
      "    self.model = DiffusionWrapper(unet_config, conditioning_key, aux_unet_config)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/models/diffusion/ddpm.py\", line 1535, in __init__\n",
      "    self.aux_diffusion_model = instantiate_from_config(aux_model_config)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/ldm/util.py\", line 81, in instantiate_from_config\n",
      "    if not \"target\" in config:\n",
      "TypeError: argument of type 'NoneType' is not iterable\n",
      "mv: cannot stat 'outputs/txt2img-samples/*.png': No such file or directory\n",
      "Global seed set to 23\n",
      "Running on GPUs 0,\n",
      "{'model': {'base_learning_rate': 1e-06, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'reg_weight': 1.0, 'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'image', 'cond_stage_key': 'caption', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': True, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'embedding_reg_weight': 0.0, 'unfreeze_model': True, 'model_lr': 1e-06, 'personalization_config': {'target': 'ldm.modules.embedding_manager.EmbeddingManager', 'params': {'placeholder_strings': ['*'], 'initializer_words': ['sculpture'], 'per_image_tokens': False, 'num_vectors_per_token': 1, 'progressive_words': False}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}}, 'aux_unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False, 'use_fp16': True}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 512, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenCLIPEmbedder'}}}, 'data': {'target': 'main.DataModuleFromConfig', 'params': {'batch_size': 1, 'num_workers': 1, 'wrap': False, 'train': {'target': 'ldm.data.personalized.PersonalizedBase', 'params': {'size': 512, 'set': 'train', 'per_image_tokens': False, 'repeats': 100, 'coarse_class_text': 'style', 'data_root': './training_images/test_20221126-043935', 'placeholder_token': 'test', 'token_only': False}}, 'reg': {'target': 'ldm.data.personalized.PersonalizedBase', 'params': {'size': 512, 'set': 'train', 'reg': True, 'per_image_tokens': False, 'repeats': 10, 'data_root': './regularization_images/style', 'coarse_class_text': 'style', 'placeholder_token': 'test'}}, 'validation': {'target': 'ldm.data.personalized.PersonalizedBase', 'params': {'size': 512, 'set': 'val', 'per_image_tokens': False, 'repeats': 10, 'coarse_class_text': 'style', 'placeholder_token': 'test', 'data_root': './training_images/test_20221126-043935'}}}}, '\\\\': None}\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 685, in <module>\n",
      "    model = load_model_from_config(config, opt.actual_resume)\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 30, in load_model_from_config\n",
      "    exit(-1)\n",
      "  File \"/opt/conda/lib/python3.9/_sitebuiltins.py\", line 26, in __call__\n",
      "    raise SystemExit(code)\n",
      "SystemExit: -1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pai/jupyter/fine_tune/exp/Dreambooth-Stable-Diffusion/main.py\", line 898, in <module>\n",
      "    if trainer.global_rank == 0:\n",
      "NameError: name 'trainer' is not defined\n"
     ]
    }
   ],
   "source": [
    "%env USE_MEMORY_EFFICIENT_ATTENTION=1\n",
    "# 定义新变量\n",
    "def get_format_ts():\n",
    "    import time\n",
    "    from datetime import datetime\n",
    "    return datetime.fromtimestamp(int(time.time())).strftime('%Y%m%d-%H%M%S')\n",
    "class_token = \"style\"  # 这个变量是要训练的内容的类目，要用具有实际含义的词，如要训练一种特殊风格的椅子，就用chair, 训练特殊风格的人物，就用person, etc， 如果是一类风格的话，就用style\n",
    "prompt_token = \"test\" # 这个变量要用模型当中没有出现过的词语\n",
    "resume_model = \"model.ckpt\"  # 注意，这里是模型训练的启动点，意思是模型基于已有的哪个模型训练，在训练前问下良伟\n",
    "# resume_model = \"model.ckpt\"\n",
    "\n",
    "is_gen_training_images = True\n",
    "is_gen_reg_images = True\n",
    "reg_count = 4\n",
    "training_image_path = None\n",
    "max_training_steps=100\n",
    "train_concept(class_token, prompt_token, resume_model, is_gen_training_images, is_gen_reg_images, reg_count, training_image_path,max_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf62be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse, os, sys, datetime, glob, importlib, csv\r\n",
      "from ldm.modules.pruningckptio import PruningCheckpointIO\r\n",
      "import numpy as np\r\n",
      "import time\r\n",
      "import torch\r\n",
      "\r\n",
      "import torchvision\r\n",
      "import pytorch_lightning as pl\r\n",
      "\r\n",
      "from packaging import version\r\n",
      "from omegaconf import OmegaConf\r\n",
      "from torch.utils.data import random_split, DataLoader, Dataset, Subset\r\n",
      "from functools import partial\r\n",
      "from PIL import Image\r\n",
      "\r\n",
      "from pytorch_lightning import seed_everything\r\n",
      "from pytorch_lightning.trainer import Trainer\r\n",
      "from pytorch_lightning.callbacks import ModelCheckpoint, Callback, LearningRateMonitor\r\n",
      "from pytorch_lightning.utilities.distributed import rank_zero_only\r\n",
      "from pytorch_lightning.utilities import rank_zero_info\r\n",
      "\r\n",
      "from ldm.data.base import Txt2ImgIterableBaseDataset\r\n",
      "from ldm.util import instantiate_from_config\r\n",
      "\r\n",
      "## Un-comment this for windows\r\n",
      "## os.environ[\"PL_TORCH_DISTRIBUTED_BACKEND\"] = \"gloo\"\r\n",
      "\r\n",
      "def load_model_from_config(config, ckpt, verbose=False):\r\n",
      "    print(config)\r\n",
      "    exit(-1)\r\n",
      "    print(f\"Loading model from {ckpt}\")\r\n",
      "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\r\n",
      "    sd = pl_sd[\"state_dict\"]\r\n",
      "    config.model.params.ckpt_path = ckpt\r\n",
      "    model = instantiate_from_config(config.model)\r\n",
      "    m, u = model.load_state_dict(sd, strict=False)\r\n",
      "    if len(m) > 0 and verbose:\r\n",
      "        print(\"missing keys:\")\r\n",
      "        print(m)\r\n",
      "    if len(u) > 0 and verbose:\r\n",
      "        print(\"unexpected keys:\")\r\n",
      "        print(u)\r\n",
      "\r\n",
      "    model.cuda()\r\n",
      "    return model\r\n",
      "\r\n",
      "def get_parser(**parser_kwargs):\r\n",
      "    def str2bool(v):\r\n",
      "        if isinstance(v, bool):\r\n",
      "            return v\r\n",
      "        if v.lower() in (\"yes\", \"true\", \"t\", \"y\", \"1\"):\r\n",
      "            return True\r\n",
      "        elif v.lower() in (\"no\", \"false\", \"f\", \"n\", \"0\"):\r\n",
      "            return False\r\n",
      "        else:\r\n",
      "            raise argparse.ArgumentTypeError(\"Boolean value expected.\")\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser(**parser_kwargs)\r\n",
      "    parser.add_argument(\r\n",
      "        \"-n\",\r\n",
      "        \"--name\",\r\n",
      "        type=str,\r\n",
      "        const=True,\r\n",
      "        default=\"\",\r\n",
      "        nargs=\"?\",\r\n",
      "        help=\"postfix for logdir\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-r\",\r\n",
      "        \"--resume\",\r\n",
      "        type=str,\r\n",
      "        const=True,\r\n",
      "        default=\"\",\r\n",
      "        nargs=\"?\",\r\n",
      "        help=\"resume from logdir or checkpoint in logdir\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-b\",\r\n",
      "        \"--base\",\r\n",
      "        nargs=\"*\",\r\n",
      "        metavar=\"base_config.yaml\",\r\n",
      "        help=\"paths to base configs. Loaded from left-to-right. \"\r\n",
      "             \"Parameters can be overwritten or added with command-line options of the form `--key value`.\",\r\n",
      "        default=list(),\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-t\",\r\n",
      "        \"--train\",\r\n",
      "        type=str2bool,\r\n",
      "        const=True,\r\n",
      "        default=False,\r\n",
      "        nargs=\"?\",\r\n",
      "        help=\"train\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"--no-test\",\r\n",
      "        type=str2bool,\r\n",
      "        const=True,\r\n",
      "        default=False,\r\n",
      "        nargs=\"?\",\r\n",
      "        help=\"disable test\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-p\",\r\n",
      "        \"--project\",\r\n",
      "        help=\"name of new or path to existing project\"\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-d\",\r\n",
      "        \"--debug\",\r\n",
      "        type=str2bool,\r\n",
      "        nargs=\"?\",\r\n",
      "        const=True,\r\n",
      "        default=False,\r\n",
      "        help=\"enable post-mortem debugging\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-s\",\r\n",
      "        \"--seed\",\r\n",
      "        type=int,\r\n",
      "        default=23,\r\n",
      "        help=\"seed for seed_everything\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-f\",\r\n",
      "        \"--postfix\",\r\n",
      "        type=str,\r\n",
      "        default=\"\",\r\n",
      "        help=\"post-postfix for default name\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"-l\",\r\n",
      "        \"--logdir\",\r\n",
      "        type=str,\r\n",
      "        default=\"logs\",\r\n",
      "        help=\"directory for logging dat shit\",\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        \"--scale_lr\",\r\n",
      "        type=str2bool,\r\n",
      "        nargs=\"?\",\r\n",
      "        const=False,\r\n",
      "        default=False,\r\n",
      "        help=\"scale base-lr by ngpu * batch_size * n_accumulate\",\r\n",
      "    )\r\n",
      "\r\n",
      "    parser.add_argument(\r\n",
      "        \"--datadir_in_name\",\r\n",
      "        type=str2bool,\r\n",
      "        nargs=\"?\",\r\n",
      "        const=True,\r\n",
      "        default=True,\r\n",
      "        help=\"Prepend the final directory in the data_root to the output directory name\")\r\n",
      "\r\n",
      "    parser.add_argument(\r\n",
      "        \"--max_training_steps\",\r\n",
      "        type=int,\r\n",
      "        required=True,\r\n",
      "        help=\"Number of training steps to run\")\r\n",
      "\r\n",
      "    parser.add_argument(\r\n",
      "        \"--token\",\r\n",
      "        type=str,\r\n",
      "        required=True,\r\n",
      "        help=\"Unique token you want to represent your trained model. Ex: firstNameLastName.\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--token_only\", \r\n",
      "        type=str2bool,\r\n",
      "        const=True,\r\n",
      "        default=False,\r\n",
      "        nargs=\"?\",\r\n",
      "        help=\"Train only using the token and no class.\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--actual_resume\", \r\n",
      "        type=str,\r\n",
      "        required=True,\r\n",
      "        help=\"Path to model to actually resume from\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--data_root\", \r\n",
      "        type=str, \r\n",
      "        required=True, \r\n",
      "        help=\"Path to directory with training images\")\r\n",
      "    \r\n",
      "    parser.add_argument(\"--reg_data_root\", \r\n",
      "        type=str, \r\n",
      "        required=False, \r\n",
      "        help=\"Path to directory with regularization images\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--embedding_manager_ckpt\", \r\n",
      "        type=str, \r\n",
      "        default=\"\", \r\n",
      "        help=\"Initialize embedding manager from a checkpoint\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--class_word\", \r\n",
      "        type=str,\r\n",
      "        required=False,\r\n",
      "        help=\"Match class_word to the category of images you want to train. Example: 'man', 'woman', or 'dog'.\")\r\n",
      "\r\n",
      "    parser.add_argument(\"--init_words\", \r\n",
      "        type=str, \r\n",
      "        help=\"Comma separated list of words used to initialize the embeddigs for training.\")\r\n",
      "\r\n",
      "    return parser\r\n",
      "\r\n",
      "\r\n",
      "def nondefault_trainer_args(opt):\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser = Trainer.add_argparse_args(parser)\r\n",
      "    args = parser.parse_args([])\r\n",
      "    return sorted(k for k in vars(args) if getattr(opt, k) != getattr(args, k))\r\n",
      "\r\n",
      "\r\n",
      "class WrappedDataset(Dataset):\r\n",
      "    \"\"\"Wraps an arbitrary object with __len__ and __getitem__ into a pytorch dataset\"\"\"\r\n",
      "\r\n",
      "    def __init__(self, dataset):\r\n",
      "        self.data = dataset\r\n",
      "\r\n",
      "    def __len__(self):\r\n",
      "        return len(self.data)\r\n",
      "\r\n",
      "    def __getitem__(self, idx):\r\n",
      "        return self.data[idx]\r\n",
      "\r\n",
      "\r\n",
      "def worker_init_fn(_):\r\n",
      "    worker_info = torch.utils.data.get_worker_info()\r\n",
      "\r\n",
      "    dataset = worker_info.dataset\r\n",
      "    worker_id = worker_info.id\r\n",
      "\r\n",
      "    if isinstance(dataset, Txt2ImgIterableBaseDataset):\r\n",
      "        split_size = dataset.num_records // worker_info.num_workers\r\n",
      "        # reset num_records to the true number to retain reliable length information\r\n",
      "        dataset.sample_ids = dataset.valid_ids[worker_id * split_size:(worker_id + 1) * split_size]\r\n",
      "        current_id = np.random.choice(len(np.random.get_state()[1]), 1)\r\n",
      "        return np.random.seed(np.random.get_state()[1][current_id] + worker_id)\r\n",
      "    else:\r\n",
      "        return np.random.seed(np.random.get_state()[1][0] + worker_id)\r\n",
      "\r\n",
      "class ConcatDataset(Dataset):\r\n",
      "    def __init__(self, *datasets):\r\n",
      "        self.datasets = datasets\r\n",
      "\r\n",
      "    def __getitem__(self, idx):\r\n",
      "        return tuple(d[idx] for d in self.datasets)\r\n",
      "\r\n",
      "    def __len__(self):\r\n",
      "        return min(len(d) for d in self.datasets)\r\n",
      "    \r\n",
      "class DataModuleFromConfig(pl.LightningDataModule):\r\n",
      "    def __init__(self, batch_size, train=None, reg = None, validation=None, test=None, predict=None,\r\n",
      "                 wrap=False, num_workers=None, shuffle_test_loader=False, use_worker_init_fn=False,\r\n",
      "                 shuffle_val_dataloader=False):\r\n",
      "        super().__init__()\r\n",
      "        self.batch_size = batch_size\r\n",
      "        self.dataset_configs = dict()\r\n",
      "        self.num_workers = num_workers if num_workers is not None else batch_size * 2\r\n",
      "        self.use_worker_init_fn = use_worker_init_fn\r\n",
      "        if train is not None:\r\n",
      "            self.dataset_configs[\"train\"] = train\r\n",
      "        if reg is not None:\r\n",
      "            self.dataset_configs[\"reg\"] = reg\r\n",
      "        \r\n",
      "        self.train_dataloader = self._train_dataloader\r\n",
      "        \r\n",
      "        if validation is not None:\r\n",
      "            self.dataset_configs[\"validation\"] = validation\r\n",
      "            self.val_dataloader = partial(self._val_dataloader, shuffle=shuffle_val_dataloader)\r\n",
      "        if test is not None:\r\n",
      "            self.dataset_configs[\"test\"] = test\r\n",
      "            self.test_dataloader = partial(self._test_dataloader, shuffle=shuffle_test_loader)\r\n",
      "        if predict is not None:\r\n",
      "            self.dataset_configs[\"predict\"] = predict\r\n",
      "            self.predict_dataloader = self._predict_dataloader\r\n",
      "        self.wrap = wrap\r\n",
      "\r\n",
      "    def prepare_data(self):\r\n",
      "        for data_cfg in self.dataset_configs.values():\r\n",
      "            instantiate_from_config(data_cfg)\r\n",
      "\r\n",
      "    def setup(self, stage=None):\r\n",
      "        self.datasets = dict(\r\n",
      "            (k, instantiate_from_config(self.dataset_configs[k]))\r\n",
      "            for k in self.dataset_configs)\r\n",
      "        if self.wrap:\r\n",
      "            for k in self.datasets:\r\n",
      "                self.datasets[k] = WrappedDataset(self.datasets[k])\r\n",
      "\r\n",
      "    def _train_dataloader(self):\r\n",
      "        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)\r\n",
      "        if is_iterable_dataset or self.use_worker_init_fn:\r\n",
      "            init_fn = worker_init_fn\r\n",
      "        else:\r\n",
      "            init_fn = None\r\n",
      "\r\n",
      "        train_set = self.datasets[\"train\"]\r\n",
      "        if 'reg' in self.datasets:\r\n",
      "            reg_set = self.datasets[\"reg\"]\r\n",
      "            train_set = ConcatDataset(train_set, reg_set)\r\n",
      "\r\n",
      "        return DataLoader(train_set, batch_size=self.batch_size,\r\n",
      "                          num_workers=self.num_workers, shuffle=False if is_iterable_dataset else True,\r\n",
      "                          worker_init_fn=init_fn)\r\n",
      "\r\n",
      "    def _val_dataloader(self, shuffle=False):\r\n",
      "        if isinstance(self.datasets['validation'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:\r\n",
      "            init_fn = worker_init_fn\r\n",
      "        else:\r\n",
      "            init_fn = None\r\n",
      "        return DataLoader(self.datasets[\"validation\"],\r\n",
      "                          batch_size=self.batch_size,\r\n",
      "                          num_workers=self.num_workers,\r\n",
      "                          worker_init_fn=init_fn,\r\n",
      "                          shuffle=shuffle)\r\n",
      "\r\n",
      "    def _test_dataloader(self, shuffle=False):\r\n",
      "        is_iterable_dataset = isinstance(self.datasets['train'], Txt2ImgIterableBaseDataset)\r\n",
      "        if is_iterable_dataset or self.use_worker_init_fn:\r\n",
      "            init_fn = worker_init_fn\r\n",
      "        else:\r\n",
      "            init_fn = None\r\n",
      "\r\n",
      "        # do not shuffle dataloader for iterable dataset\r\n",
      "        shuffle = shuffle and (not is_iterable_dataset)\r\n",
      "\r\n",
      "        return DataLoader(self.datasets[\"test\"], batch_size=self.batch_size,\r\n",
      "                          num_workers=self.num_workers, worker_init_fn=init_fn, shuffle=shuffle)\r\n",
      "\r\n",
      "    def _predict_dataloader(self, shuffle=False):\r\n",
      "        if isinstance(self.datasets['predict'], Txt2ImgIterableBaseDataset) or self.use_worker_init_fn:\r\n",
      "            init_fn = worker_init_fn\r\n",
      "        else:\r\n",
      "            init_fn = None\r\n",
      "        return DataLoader(self.datasets[\"predict\"], batch_size=self.batch_size,\r\n",
      "                          num_workers=self.num_workers, worker_init_fn=init_fn)\r\n",
      "\r\n",
      "\r\n",
      "class SetupCallback(Callback):\r\n",
      "    def __init__(self, resume, now, logdir, ckptdir, cfgdir, config, lightning_config):\r\n",
      "        super().__init__()\r\n",
      "        self.resume = resume\r\n",
      "        self.now = now\r\n",
      "        self.logdir = logdir\r\n",
      "        self.ckptdir = ckptdir\r\n",
      "        self.cfgdir = cfgdir\r\n",
      "        self.config = config\r\n",
      "        self.lightning_config = lightning_config\r\n",
      "\r\n",
      "    def on_keyboard_interrupt(self, trainer, pl_module):\r\n",
      "        if trainer.global_rank == 0:\r\n",
      "            print(\"Summoning checkpoint.\")\r\n",
      "            ckpt_path = os.path.join(self.ckptdir, \"last.ckpt\")\r\n",
      "            trainer.save_checkpoint(ckpt_path)\r\n",
      "\r\n",
      "    def on_pretrain_routine_start(self, trainer, pl_module):\r\n",
      "        if trainer.global_rank == 0:\r\n",
      "            # Create logdirs and save configs\r\n",
      "            os.makedirs(self.logdir, exist_ok=True)\r\n",
      "            os.makedirs(self.ckptdir, exist_ok=True)\r\n",
      "            os.makedirs(self.cfgdir, exist_ok=True)\r\n",
      "\r\n",
      "            if \"callbacks\" in self.lightning_config:\r\n",
      "                if 'metrics_over_trainsteps_checkpoint' in self.lightning_config['callbacks']:\r\n",
      "                    os.makedirs(os.path.join(self.ckptdir, 'trainstep_checkpoints'), exist_ok=True)\r\n",
      "            print(\"Project config\")\r\n",
      "            print(OmegaConf.to_yaml(self.config))\r\n",
      "            OmegaConf.save(self.config,\r\n",
      "                           os.path.join(self.cfgdir, \"{}-project.yaml\".format(self.now)))\r\n",
      "\r\n",
      "            print(\"Lightning config\")\r\n",
      "            print(OmegaConf.to_yaml(self.lightning_config))\r\n",
      "            OmegaConf.save(OmegaConf.create({\"lightning\": self.lightning_config}),\r\n",
      "                           os.path.join(self.cfgdir, \"{}-lightning.yaml\".format(self.now)))\r\n",
      "\r\n",
      "        else:\r\n",
      "            # ModelCheckpoint callback created log directory --- remove it\r\n",
      "            if not self.resume and os.path.exists(self.logdir):\r\n",
      "                dst, name = os.path.split(self.logdir)\r\n",
      "                dst = os.path.join(dst, \"child_runs\", name)\r\n",
      "                os.makedirs(os.path.split(dst)[0], exist_ok=True)\r\n",
      "                try:\r\n",
      "                    os.rename(self.logdir, dst)\r\n",
      "                except FileNotFoundError:\r\n",
      "                    pass\r\n",
      "\r\n",
      "\r\n",
      "class ImageLogger(Callback):\r\n",
      "    def __init__(self, batch_frequency, max_images, clamp=True, increase_log_steps=True,\r\n",
      "                 rescale=True, disabled=False, log_on_batch_idx=False, log_first_step=False,\r\n",
      "                 log_images_kwargs=None):\r\n",
      "        super().__init__()\r\n",
      "        self.rescale = rescale\r\n",
      "        self.batch_freq = batch_frequency\r\n",
      "        self.max_images = max_images\r\n",
      "        self.logger_log_images = {\r\n",
      "            pl.loggers.TestTubeLogger: self._testtube,\r\n",
      "        }\r\n",
      "        self.log_steps = [2 ** n for n in range(int(np.log2(self.batch_freq)) + 1)]\r\n",
      "        if not increase_log_steps:\r\n",
      "            self.log_steps = [self.batch_freq]\r\n",
      "        self.clamp = clamp\r\n",
      "        self.disabled = disabled\r\n",
      "        self.log_on_batch_idx = log_on_batch_idx\r\n",
      "        self.log_images_kwargs = log_images_kwargs if log_images_kwargs else {}\r\n",
      "        self.log_first_step = log_first_step\r\n",
      "\r\n",
      "    @rank_zero_only\r\n",
      "    def _testtube(self, pl_module, images, batch_idx, split):\r\n",
      "        for k in images:\r\n",
      "            grid = torchvision.utils.make_grid(images[k])\r\n",
      "            grid = (grid + 1.0) / 2.0  # -1,1 -> 0,1; c,h,w\r\n",
      "\r\n",
      "            tag = f\"{split}/{k}\"\r\n",
      "            pl_module.logger.experiment.add_image(\r\n",
      "                tag, grid,\r\n",
      "                global_step=pl_module.global_step)\r\n",
      "\r\n",
      "    @rank_zero_only\r\n",
      "    def log_local(self, save_dir, split, images,\r\n",
      "                  global_step, current_epoch, batch_idx):\r\n",
      "        root = os.path.join(save_dir, \"images\", split)\r\n",
      "        for k in images:\r\n",
      "            grid = torchvision.utils.make_grid(images[k], nrow=4)\r\n",
      "            if self.rescale:\r\n",
      "                grid = (grid + 1.0) / 2.0  # -1,1 -> 0,1; c,h,w\r\n",
      "            grid = grid.transpose(0, 1).transpose(1, 2).squeeze(-1)\r\n",
      "            grid = grid.numpy()\r\n",
      "            grid = (grid * 255).astype(np.uint8)\r\n",
      "            filename = \"{}_globalstep-{:05}_epoch-{:01}_batch-{:04}.jpg\".format(\r\n",
      "                k,\r\n",
      "                global_step,\r\n",
      "                current_epoch,\r\n",
      "                batch_idx)\r\n",
      "            path = os.path.join(root, filename)\r\n",
      "            os.makedirs(os.path.split(path)[0], exist_ok=True)\r\n",
      "            Image.fromarray(grid).save(path)\r\n",
      "\r\n",
      "    def log_img(self, pl_module, batch, batch_idx, split=\"train\"):\r\n",
      "        check_idx = batch_idx if self.log_on_batch_idx else pl_module.global_step\r\n",
      "        if (self.check_frequency(check_idx) and  # batch_idx % self.batch_freq == 0\r\n",
      "                hasattr(pl_module, \"log_images\") and\r\n",
      "                callable(pl_module.log_images) and\r\n",
      "                self.max_images > 0):\r\n",
      "            logger = type(pl_module.logger)\r\n",
      "\r\n",
      "            is_train = pl_module.training\r\n",
      "            if is_train:\r\n",
      "                pl_module.eval()\r\n",
      "\r\n",
      "            with torch.no_grad():\r\n",
      "                images = pl_module.log_images(batch, split=split, **self.log_images_kwargs)\r\n",
      "\r\n",
      "            for k in images:\r\n",
      "                N = min(images[k].shape[0], self.max_images)\r\n",
      "                images[k] = images[k][:N]\r\n",
      "                if isinstance(images[k], torch.Tensor):\r\n",
      "                    images[k] = images[k].detach().cpu()\r\n",
      "                    if self.clamp:\r\n",
      "                        images[k] = torch.clamp(images[k], -1., 1.)\r\n",
      "\r\n",
      "            self.log_local(pl_module.logger.save_dir, split, images,\r\n",
      "                           pl_module.global_step, pl_module.current_epoch, batch_idx)\r\n",
      "\r\n",
      "            logger_log_images = self.logger_log_images.get(logger, lambda *args, **kwargs: None)\r\n",
      "            logger_log_images(pl_module, images, pl_module.global_step, split)\r\n",
      "\r\n",
      "            if is_train:\r\n",
      "                pl_module.train()\r\n",
      "\r\n",
      "    def check_frequency(self, check_idx):\r\n",
      "        if ((check_idx % self.batch_freq) == 0 or (check_idx in self.log_steps)) and (\r\n",
      "                check_idx > 0 or self.log_first_step):\r\n",
      "            try:\r\n",
      "                self.log_steps.pop(0)\r\n",
      "            except IndexError as e:\r\n",
      "                print(e)\r\n",
      "                pass\r\n",
      "            return True\r\n",
      "        return False\r\n",
      "\r\n",
      "    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\r\n",
      "        if not self.disabled and (pl_module.global_step > 0 or self.log_first_step):\r\n",
      "            self.log_img(pl_module, batch, batch_idx, split=\"train\")\r\n",
      "\r\n",
      "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\r\n",
      "        pass\r\n",
      "        #if not self.disabled and pl_module.global_step > 0:\r\n",
      "            #self.log_img(pl_module, batch, batch_idx, split=\"val\")\r\n",
      "        #if hasattr(pl_module, 'calibrate_grad_norm'):\r\n",
      "            #if (pl_module.calibrate_grad_norm and batch_idx % 25 == 0) and batch_idx > 0:\r\n",
      "                #self.log_gradients(trainer, pl_module, batch_idx=batch_idx)\r\n",
      "\r\n",
      "\r\n",
      "class CUDACallback(Callback):\r\n",
      "    # see https://github.com/SeanNaren/minGPT/blob/master/mingpt/callback.py\r\n",
      "    def on_train_epoch_start(self, trainer, pl_module):\r\n",
      "        # Reset the memory use counter\r\n",
      "        torch.cuda.reset_peak_memory_stats(trainer.root_gpu)\r\n",
      "        torch.cuda.synchronize(trainer.root_gpu)\r\n",
      "        self.start_time = time.time()\r\n",
      "\r\n",
      "    def on_train_epoch_end(self, trainer, pl_module):\r\n",
      "        torch.cuda.synchronize(trainer.root_gpu)\r\n",
      "        max_memory = torch.cuda.max_memory_allocated(trainer.root_gpu) / 2 ** 20\r\n",
      "        epoch_time = time.time() - self.start_time\r\n",
      "\r\n",
      "        try:\r\n",
      "            max_memory = trainer.training_type_plugin.reduce(max_memory)\r\n",
      "            epoch_time = trainer.training_type_plugin.reduce(epoch_time)\r\n",
      "\r\n",
      "            rank_zero_info(f\"Average Epoch time: {epoch_time:.2f} seconds\")\r\n",
      "            rank_zero_info(f\"Average Peak memory {max_memory:.2f}MiB\")\r\n",
      "        except AttributeError:\r\n",
      "            pass\r\n",
      "\r\n",
      "class ModeSwapCallback(Callback):\r\n",
      "\r\n",
      "    def __init__(self, swap_step=2000):\r\n",
      "        super().__init__()\r\n",
      "        self.is_frozen = False\r\n",
      "        self.swap_step = swap_step\r\n",
      "\r\n",
      "    def on_train_epoch_start(self, trainer, pl_module):\r\n",
      "        if trainer.global_step < self.swap_step and not self.is_frozen:\r\n",
      "            self.is_frozen = True\r\n",
      "            trainer.optimizers = [pl_module.configure_opt_embedding()]\r\n",
      "\r\n",
      "        if trainer.global_step > self.swap_step and self.is_frozen:\r\n",
      "            self.is_frozen = False\r\n",
      "            trainer.optimizers = [pl_module.configure_opt_model()]\r\n",
      "\r\n",
      "if __name__ == \"__main__\":\r\n",
      "    # custom parser to specify config files, train, test and debug mode,\r\n",
      "    # postfix, resume.\r\n",
      "    # `--key value` arguments are interpreted as arguments to the trainer.\r\n",
      "    # `nested.key=value` arguments are interpreted as config parameters.\r\n",
      "    # configs are merged from left-to-right followed by command line parameters.\r\n",
      "\r\n",
      "    # model:\r\n",
      "    #   base_learning_rate: float\r\n",
      "    #   target: path to lightning module\r\n",
      "    #   params:\r\n",
      "    #       key: value\r\n",
      "    # data:\r\n",
      "    #   target: main.DataModuleFromConfig\r\n",
      "    #   params:\r\n",
      "    #      batch_size: int\r\n",
      "    #      wrap: bool\r\n",
      "    #      train:\r\n",
      "    #          target: path to train dataset\r\n",
      "    #          params:\r\n",
      "    #              key: value\r\n",
      "    #      validation:\r\n",
      "    #          target: path to validation dataset\r\n",
      "    #          params:\r\n",
      "    #              key: value\r\n",
      "    #      test:\r\n",
      "    #          target: path to test dataset\r\n",
      "    #          params:\r\n",
      "    #              key: value\r\n",
      "    # lightning: (optional, has sane defaults and can be specified on cmdline)\r\n",
      "    #   trainer:\r\n",
      "    #       additional arguments to trainer\r\n",
      "    #   logger:\r\n",
      "    #       logger to instantiate\r\n",
      "    #   modelcheckpoint:\r\n",
      "    #       modelcheckpoint to instantiate\r\n",
      "    #   callbacks:\r\n",
      "    #       callback1:\r\n",
      "    #           target: importpath\r\n",
      "    #           params:\r\n",
      "    #               key: value\r\n",
      "\r\n",
      "    now = datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\r\n",
      "\r\n",
      "    # add cwd for convenience and to make classes in this file available when\r\n",
      "    # running as `python main.py`\r\n",
      "    # (in particular `main.DataModuleFromConfig`)\r\n",
      "    sys.path.append(os.getcwd())\r\n",
      "\r\n",
      "    parser = get_parser()\r\n",
      "    parser = Trainer.add_argparse_args(parser)\r\n",
      "\r\n",
      "    opt, unknown = parser.parse_known_args()\r\n",
      "    if opt.name and opt.resume:\r\n",
      "        raise ValueError(\r\n",
      "            \"-n/--name and -r/--resume cannot be specified both.\"\r\n",
      "            \"If you want to resume training in a new log folder, \"\r\n",
      "            \"use -n/--name in combination with --resume_from_checkpoint\"\r\n",
      "        )\r\n",
      "    if opt.resume:\r\n",
      "        if not os.path.exists(opt.resume):\r\n",
      "            raise ValueError(\"Cannot find {}\".format(opt.resume))\r\n",
      "        if os.path.isfile(opt.resume):\r\n",
      "            paths = opt.resume.split(\"/\")\r\n",
      "            # idx = len(paths)-paths[::-1].index(\"logs\")+1\r\n",
      "            # logdir = \"/\".join(paths[:idx])\r\n",
      "            logdir = \"/\".join(paths[:-2])\r\n",
      "            ckpt = opt.resume\r\n",
      "        else:\r\n",
      "            assert os.path.isdir(opt.resume), opt.resume\r\n",
      "            logdir = opt.resume.rstrip(\"/\")\r\n",
      "            ckpt = os.path.join(logdir, \"checkpoints\", \"last.ckpt\")\r\n",
      "\r\n",
      "        opt.resume_from_checkpoint = ckpt\r\n",
      "        base_configs = sorted(glob.glob(os.path.join(logdir, \"configs/*.yaml\")))\r\n",
      "        opt.base = base_configs + opt.base\r\n",
      "        _tmp = logdir.split(\"/\")\r\n",
      "        nowname = _tmp[-1]\r\n",
      "    else:\r\n",
      "        if opt.name:\r\n",
      "            name = \"_\" + opt.name\r\n",
      "        elif opt.base:\r\n",
      "            cfg_fname = os.path.split(opt.base[0])[-1]\r\n",
      "            cfg_name = os.path.splitext(cfg_fname)[0]\r\n",
      "            name = \"_\" + cfg_name\r\n",
      "        else:\r\n",
      "            name = \"\"\r\n",
      "\r\n",
      "        if opt.datadir_in_name:\r\n",
      "            now = os.path.basename(os.path.normpath(opt.data_root)) + now\r\n",
      "            \r\n",
      "        nowname = now + name + opt.postfix\r\n",
      "        logdir = os.path.join(opt.logdir, nowname)\r\n",
      "\r\n",
      "    ckptdir = os.path.join(logdir, \"checkpoints\")\r\n",
      "    cfgdir = os.path.join(logdir, \"configs\")\r\n",
      "    seed_everything(opt.seed)\r\n",
      "\r\n",
      "    try:\r\n",
      "        # init and save configs\r\n",
      "        configs = [OmegaConf.load(cfg) for cfg in opt.base]\r\n",
      "        cli = OmegaConf.from_dotlist(unknown)\r\n",
      "        config = OmegaConf.merge(*configs, cli)\r\n",
      "        lightning_config = config.pop(\"lightning\", OmegaConf.create())\r\n",
      "\r\n",
      "        # merge trainer cli with config\r\n",
      "        trainer_config = lightning_config.get(\"trainer\", OmegaConf.create())\r\n",
      "\r\n",
      "        # Set the steps\r\n",
      "        trainer_config.max_steps = opt.max_training_steps\r\n",
      "\r\n",
      "        for k in nondefault_trainer_args(opt):\r\n",
      "            trainer_config[k] = getattr(opt, k)\r\n",
      "        if not \"gpus\" in trainer_config:\r\n",
      "            del trainer_config[\"accelerator\"]\r\n",
      "            cpu = True\r\n",
      "        else:\r\n",
      "            gpuinfo = trainer_config[\"gpus\"]\r\n",
      "            print(f\"Running on GPUs {gpuinfo}\")\r\n",
      "            cpu = False\r\n",
      "        trainer_opt = argparse.Namespace(**trainer_config)\r\n",
      "        lightning_config.trainer = trainer_config\r\n",
      "\r\n",
      "        if opt.init_words:\r\n",
      "            config.model.params.personalization_config.params.initializer_words = [ \r\n",
      "                    init_word.strip() for init_word in opt.init_words.split(',')\r\n",
      "                ]\r\n",
      "\r\n",
      "        # if opt.init_word:\r\n",
      "        #     config.model.params.personalization_config.params.initializer_words[0] = opt.init_word\r\n",
      "\r\n",
      "        # Setup the token and class word to get passed to personalized.py\r\n",
      "        if not opt.reg_data_root:\r\n",
      "            config.data.params.reg = None\r\n",
      "        else:\r\n",
      "            config.data.params.reg.params.data_root = opt.reg_data_root\r\n",
      "            config.data.params.reg.params.coarse_class_text = opt.class_word\r\n",
      "            config.data.params.reg.params.placeholder_token = opt.token\r\n",
      "        \r\n",
      "\r\n",
      "        if opt.class_word:\r\n",
      "            config.data.params.train.params.coarse_class_text = opt.class_word\r\n",
      "            config.data.params.validation.params.coarse_class_text = opt.class_word\r\n",
      "\r\n",
      "        config.data.params.train.params.data_root = opt.data_root\r\n",
      "        config.data.params.train.params.placeholder_token = opt.token\r\n",
      "        config.data.params.train.params.token_only = opt.token_only or not opt.class_word\r\n",
      "\r\n",
      "        config.data.params.validation.params.placeholder_token = opt.token\r\n",
      "        config.data.params.validation.params.data_root = opt.data_root\r\n",
      "\r\n",
      "        if opt.actual_resume:\r\n",
      "            model = load_model_from_config(config, opt.actual_resume)\r\n",
      "        else:\r\n",
      "            model = instantiate_from_config(config.model)\r\n",
      "\r\n",
      "        # trainer and callbacks\r\n",
      "        trainer_kwargs = dict()\r\n",
      "\r\n",
      "        # default logger configs\r\n",
      "        default_logger_cfgs = {\r\n",
      "            \"wandb\": {\r\n",
      "                \"target\": \"pytorch_lightning.loggers.WandbLogger\",\r\n",
      "                \"params\": {\r\n",
      "                    \"name\": nowname,\r\n",
      "                    \"save_dir\": logdir,\r\n",
      "                    \"offline\": opt.debug,\r\n",
      "                    \"id\": nowname,\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"testtube\": {\r\n",
      "                \"target\": \"pytorch_lightning.loggers.TestTubeLogger\",\r\n",
      "                \"params\": {\r\n",
      "                    \"name\": \"testtube\",\r\n",
      "                    \"save_dir\": logdir,\r\n",
      "                }\r\n",
      "            },\r\n",
      "        }\r\n",
      "        default_logger_cfg = default_logger_cfgs[\"testtube\"]\r\n",
      "        if \"logger\" in lightning_config:\r\n",
      "            logger_cfg = lightning_config.logger\r\n",
      "        else:\r\n",
      "            logger_cfg = OmegaConf.create()\r\n",
      "        logger_cfg = OmegaConf.merge(default_logger_cfg, logger_cfg)\r\n",
      "        trainer_kwargs[\"logger\"] = instantiate_from_config(logger_cfg)\r\n",
      "\r\n",
      "        # modelcheckpoint - use TrainResult/EvalResult(checkpoint_on=metric) to\r\n",
      "        # specify which metric is used to determine best models\r\n",
      "        default_modelckpt_cfg = {\r\n",
      "            \"target\": \"pytorch_lightning.callbacks.ModelCheckpoint\",\r\n",
      "            \"params\": {\r\n",
      "                \"dirpath\": ckptdir,\r\n",
      "                \"filename\": \"{epoch:06}\",\r\n",
      "                \"verbose\": True,\r\n",
      "                \"save_last\": True,\r\n",
      "            }\r\n",
      "        }\r\n",
      "        if hasattr(model, \"monitor\"):\r\n",
      "            print(f\"Monitoring {model.monitor} as checkpoint metric.\")\r\n",
      "            default_modelckpt_cfg[\"params\"][\"monitor\"] = model.monitor\r\n",
      "            default_modelckpt_cfg[\"params\"][\"save_top_k\"] = 1\r\n",
      "\r\n",
      "        if \"modelcheckpoint\" in lightning_config:\r\n",
      "            modelckpt_cfg = lightning_config.modelcheckpoint\r\n",
      "        else:\r\n",
      "            modelckpt_cfg =  OmegaConf.create()\r\n",
      "        modelckpt_cfg = OmegaConf.merge(default_modelckpt_cfg, modelckpt_cfg)\r\n",
      "        print(f\"Merged modelckpt-cfg: \\n{modelckpt_cfg}\")\r\n",
      "        if version.parse(pl.__version__) < version.parse('1.4.0'):\r\n",
      "            trainer_kwargs[\"checkpoint_callback\"] = instantiate_from_config(modelckpt_cfg)\r\n",
      "\r\n",
      "        # add callback which sets up log directory\r\n",
      "        default_callbacks_cfg = {\r\n",
      "            \"setup_callback\": {\r\n",
      "                \"target\": \"main.SetupCallback\",\r\n",
      "                \"params\": {\r\n",
      "                    \"resume\": opt.resume,\r\n",
      "                    \"now\": now,\r\n",
      "                    \"logdir\": logdir,\r\n",
      "                    \"ckptdir\": ckptdir,\r\n",
      "                    \"cfgdir\": cfgdir,\r\n",
      "                    \"config\": config,\r\n",
      "                    \"lightning_config\": lightning_config,\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"image_logger\": {\r\n",
      "                \"target\": \"main.ImageLogger\",\r\n",
      "                \"params\": {\r\n",
      "                    \"batch_frequency\": 750,\r\n",
      "                    \"max_images\": 4,\r\n",
      "                    \"clamp\": True\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"learning_rate_logger\": {\r\n",
      "                \"target\": \"main.LearningRateMonitor\",\r\n",
      "                \"params\": {\r\n",
      "                    \"logging_interval\": \"step\",\r\n",
      "                    # \"log_momentum\": True\r\n",
      "                }\r\n",
      "            },\r\n",
      "            \"cuda_callback\": {\r\n",
      "                \"target\": \"main.CUDACallback\"\r\n",
      "            },\r\n",
      "        }\r\n",
      "        if version.parse(pl.__version__) >= version.parse('1.4.0'):\r\n",
      "            default_callbacks_cfg.update({'checkpoint_callback': modelckpt_cfg})\r\n",
      "\r\n",
      "        if \"callbacks\" in lightning_config:\r\n",
      "            callbacks_cfg = lightning_config.callbacks\r\n",
      "        else:\r\n",
      "            callbacks_cfg = OmegaConf.create()\r\n",
      "\r\n",
      "        if 'metrics_over_trainsteps_checkpoint' in callbacks_cfg:\r\n",
      "            print('Caution: Saving checkpoints every n train steps without deleting. This might require some free space.')\r\n",
      "            default_metrics_over_trainsteps_ckpt_dict = {\r\n",
      "                'metrics_over_trainsteps_checkpoint': {\r\n",
      "                    \"target\": 'pytorch_lightning.callbacks.ModelCheckpoint',\r\n",
      "                    'params': {\r\n",
      "                         \"dirpath\": os.path.join(ckptdir, 'trainstep_checkpoints'),\r\n",
      "                         \"filename\": \"{epoch:06}-{step:09}\",\r\n",
      "                         \"verbose\": True,\r\n",
      "                         'save_top_k': -1,\r\n",
      "                         'every_n_train_steps': 10000,\r\n",
      "                         'save_weights_only': True\r\n",
      "                     }\r\n",
      "                }\r\n",
      "            }\r\n",
      "\r\n",
      "            default_callbacks_cfg.update(default_metrics_over_trainsteps_ckpt_dict)\r\n",
      "\r\n",
      "        callbacks_cfg = OmegaConf.merge(default_callbacks_cfg, callbacks_cfg)\r\n",
      "        if 'ignore_keys_callback' in callbacks_cfg and hasattr(trainer_opt, 'resume_from_checkpoint'):\r\n",
      "            callbacks_cfg.ignore_keys_callback.params['ckpt_path'] = trainer_opt.resume_from_checkpoint\r\n",
      "        elif 'ignore_keys_callback' in callbacks_cfg:\r\n",
      "            del callbacks_cfg['ignore_keys_callback']\r\n",
      "\r\n",
      "        trainer_kwargs[\"callbacks\"] = [instantiate_from_config(callbacks_cfg[k]) for k in callbacks_cfg]\r\n",
      "        trainer_kwargs[\"max_steps\"] = trainer_opt.max_steps\r\n",
      "        trainer_kwargs[\"plugins\"] = PruningCheckpointIO()\r\n",
      "    \r\n",
      "        trainer = Trainer.from_argparse_args(trainer_opt, **trainer_kwargs)\r\n",
      "        trainer.logdir = logdir  ###\r\n",
      "\r\n",
      "        data = instantiate_from_config(config.data)\r\n",
      "\r\n",
      "        # NOTE according to https://pytorch-lightning.readthedocs.io/en/latest/datamodules.html\r\n",
      "        # calling these ourselves should not be necessary but it is.\r\n",
      "        # lightning still takes care of proper multiprocessing though\r\n",
      "        data.prepare_data()\r\n",
      "        data.setup()\r\n",
      "        print(\"#### Data #####\")\r\n",
      "        for k in data.datasets:\r\n",
      "            print(f\"{k}, {data.datasets[k].__class__.__name__}, {len(data.datasets[k])}\")\r\n",
      "\r\n",
      "        # configure learning rate\r\n",
      "        bs, base_lr = config.data.params.batch_size, config.model.base_learning_rate\r\n",
      "        if not cpu:\r\n",
      "            ngpu = len(lightning_config.trainer.gpus.strip(\",\").split(','))\r\n",
      "        else:\r\n",
      "            ngpu = 1\r\n",
      "        if 'accumulate_grad_batches' in lightning_config.trainer:\r\n",
      "            accumulate_grad_batches = lightning_config.trainer.accumulate_grad_batches\r\n",
      "        else:\r\n",
      "            accumulate_grad_batches = 1\r\n",
      "        print(f\"accumulate_grad_batches = {accumulate_grad_batches}\")\r\n",
      "        lightning_config.trainer.accumulate_grad_batches = accumulate_grad_batches\r\n",
      "        if opt.scale_lr:\r\n",
      "            model.learning_rate = accumulate_grad_batches * ngpu * bs * base_lr\r\n",
      "            print(\r\n",
      "                \"Setting learning rate to {:.2e} = {} (accumulate_grad_batches) * {} (num_gpus) * {} (batchsize) * {:.2e} (base_lr)\".format(\r\n",
      "                    model.learning_rate, accumulate_grad_batches, ngpu, bs, base_lr))\r\n",
      "        else:\r\n",
      "            model.learning_rate = base_lr\r\n",
      "            print(\"++++ NOT USING LR SCALING ++++\")\r\n",
      "            print(f\"Setting learning rate to {model.learning_rate:.2e}\")\r\n",
      "\r\n",
      "\r\n",
      "        # allow checkpointing via USR1\r\n",
      "        def melk(*args, **kwargs):\r\n",
      "            # run all checkpoint hooks\r\n",
      "            if trainer.global_rank == 0:\r\n",
      "                print(\"Here comes the checkpoint...\")\r\n",
      "                ckpt_path = os.path.join(ckptdir, \"last.ckpt\")\r\n",
      "                trainer.save_checkpoint(ckpt_path)\r\n",
      "\r\n",
      "\r\n",
      "        def divein(*args, **kwargs):\r\n",
      "            if trainer.global_rank == 0:\r\n",
      "                import pudb;\r\n",
      "                pudb.set_trace()\r\n",
      "\r\n",
      "\r\n",
      "        import signal\r\n",
      "\r\n",
      "\r\n",
      "        # Changed to work with windows\r\n",
      "        signal.signal(signal.SIGTERM, melk)\r\n",
      "        #signal.signal(signal.SIGUSR1, melk)\r\n",
      "        signal.signal(signal.SIGTERM, divein)\r\n",
      "        #signal.signal(signal.SIGUSR2, divein)\r\n",
      "\r\n",
      "        # run\r\n",
      "        if opt.train:\r\n",
      "            try:\r\n",
      "                trainer.fit(model, data)\r\n",
      "            except Exception:\r\n",
      "                melk()\r\n",
      "                raise\r\n",
      "        if not opt.no_test and not trainer.interrupted:\r\n",
      "            trainer.test(model, data)\r\n",
      "    except Exception:\r\n",
      "        if opt.debug and trainer.global_rank == 0:\r\n",
      "            try:\r\n",
      "                import pudb as debugger\r\n",
      "            except ImportError:\r\n",
      "                import pdb as debugger\r\n",
      "            debugger.post_mortem()\r\n",
      "        raise\r\n",
      "    finally:\r\n",
      "        # move newly created debug project to debug_runs\r\n",
      "        if opt.debug and not opt.resume and trainer.global_rank == 0:\r\n",
      "            dst, name = os.path.split(logdir)\r\n",
      "            dst = os.path.join(dst, \"debug_runs\", name)\r\n",
      "            os.makedirs(os.path.split(dst)[0], exist_ok=True)\r\n",
      "            os.rename(logdir, dst)\r\n",
      "        if trainer.global_rank == 0:\r\n",
      "            print(\"Training complete. max_training_steps reached or we blew up.\")\r\n",
      "            # print(trainer.profiler.summary())"
     ]
    }
   ],
   "source": [
    "!cat main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798547d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
